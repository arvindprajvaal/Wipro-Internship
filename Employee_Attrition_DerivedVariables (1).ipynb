{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RrGkXPeUY7PE"
      },
      "outputs": [],
      "source": [
        "#Importing the neccessary libraries and reading the data\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "train_df['is_train'] = 1\n",
        "test_df['is_train'] = 0\n",
        "\n",
        "combined_df = pd.concat([train_df, test_df], axis=0)\n",
        "#Mapping the categorical variables to numerical variables\n",
        "combined_df['Gender'] = combined_df['Gender'].map({'Male': 0, 'Female': 1})\n",
        "combined_df['Job Role'] = combined_df['Job Role'].map({'Education': 0, 'Media': 1, 'Healthcare': 2, 'Technology': 3, 'Finance': 4})\n",
        "combined_df['Work-Life Balance'] = combined_df['Work-Life Balance'].map({'Poor': 0, 'Fair': 1, 'Good': 2, 'Excellent': 3})\n",
        "combined_df['Job Satisfaction'] = combined_df['Job Satisfaction'].map({'Low': 0, 'Medium': 1, 'High': 2, 'Very High': 3})\n",
        "combined_df['Performance Rating'] = combined_df['Performance Rating'].map({'Low': 0, 'Below Average': 1, 'Average': 2, 'High': 3})\n",
        "combined_df['Overtime'] = combined_df['Overtime'].map({'No': 0, 'Yes': 1})\n",
        "combined_df['Education Level'] = combined_df['Education Level'].map({\n",
        "    \"High School\": 0,\n",
        "    \"Associate Degree\": 1,\n",
        "    \"Bachelorâ€™s Degree\": 2,\n",
        "    \"Masterâ€™s Degree\": 3,\n",
        "    \"PhD\": 4\n",
        "})\n",
        "combined_df['Marital Status'] = combined_df['Marital Status'].map({'Single': 0, 'Married': 1, 'Divorced': 2})\n",
        "combined_df['Job Level'] = combined_df['Job Level'].map({'Entry': 0, 'Mid': 1, 'Senior': 2})\n",
        "combined_df['Company Size'] = combined_df['Company Size'].map({'Small': 0, 'Medium': 1, 'Large': 2})\n",
        "combined_df['Remote Work'] = combined_df['Remote Work'].map({'No': 0, 'Yes': 1})\n",
        "combined_df['Leadership Opportunities'] = combined_df['Leadership Opportunities'].map({'No': 0, 'Yes': 1})\n",
        "combined_df['Innovation Opportunities'] = combined_df['Innovation Opportunities'].map({'No': 0, 'Yes': 1})\n",
        "combined_df['Company Reputation'] = combined_df['Company Reputation'].map({'Poor': 0, 'Fair': 1, 'Good': 2, 'Excellent': 3})\n",
        "combined_df['Employee Recognition'] = combined_df['Employee Recognition'].map({'Low': 0, 'Medium': 1, 'High': 2, 'Very High': 3})\n",
        "combined_df['Attrition'] = combined_df['Attrition'].map({'Left': 0, 'Stayed': 1})\n",
        "\n",
        "\n",
        "#Adding Derived Variables\n",
        "combined_df['Tenure_Ratio'] = combined_df['Years at Company'] / (combined_df['Company Tenure'] + 1)\n",
        "combined_df['Promotion_Rate'] = combined_df['Number of Promotions'] / (combined_df['Years at Company'] + 1)\n",
        "combined_df['Distance_Category'] = pd.cut(combined_df['Distance from Home'], bins=[-1, 5, 15, 30, 1000],\n",
        "                                          labels=[0, 1, 2, 3])\n",
        "combined_df['Age_Group'] = pd.cut(combined_df['Age'], bins=[17, 30, 40, 50, 60],\n",
        "                                  labels=[0, 1, 2, 3])\n",
        "combined_df['Income_per_Level'] = combined_df['Monthly Income'] / (combined_df['Job Level'] + 1)\n",
        "combined_df['Work_Life_Satisfaction'] = (combined_df['Work-Life Balance'] + combined_df['Job Satisfaction']) / 2\n",
        "combined_df['Performance_Recognition_Score'] = (combined_df['Performance Rating'] + combined_df['Employee Recognition']) / 2\n",
        "combined_df['Education_Income_ratio'] = combined_df['Monthly Income'] / (combined_df['Education Level'] + 1)\n",
        "combined_df['Age_Joblevel']= combined_df['Age']/(combined_df['Job Level']+1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Drop Unnecessary Columns (optional)\n",
        "if 'EmployeeId' in combined_df.columns:\n",
        "    combined_df.drop(columns=['EmployeeId'], inplace=True)\n",
        "\n",
        "# Split back\n",
        "train_df = combined_df[combined_df['is_train'] == 1].drop(columns=['is_train'])\n",
        "test_df = combined_df[combined_df['is_train'] == 0].drop(columns=['is_train','Attrition'])\n",
        "\n",
        "X = train_df.drop(columns=['Attrition'])\n",
        "y = train_df['Attrition'].astype(int)\n",
        "\n",
        "#Scale and split the data to train and test splits(80:20)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "test_scaled = scaler.transform(test_df)\n",
        "\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jn_A1oOFa-O0"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        "\n",
        "\n",
        "#Importing models and metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uoZYqOtebGzE",
        "outputId": "692402c0-87e8-4c99-833a-63cedddd7e35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“Š Logistic Regression Results\n",
            "----------------------------------------\n",
            "Accuracy: 0.7229865771812081\n",
            "Precision: 0.7349148224804968\n",
            "Recall: 0.7382056612825844\n",
            "F1 Score: 0.7365565661400989\n",
            "Confusion Matrix:\n",
            " [[4002 1665]\n",
            " [1637 4616]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.71      0.71      5667\n",
            "           1       0.73      0.74      0.74      6253\n",
            "\n",
            "    accuracy                           0.72     11920\n",
            "   macro avg       0.72      0.72      0.72     11920\n",
            "weighted avg       0.72      0.72      0.72     11920\n",
            "\n",
            "\n",
            "ðŸ“Š K-Nearest Neighbors Results\n",
            "----------------------------------------\n",
            "Accuracy: 0.6711409395973155\n",
            "Precision: 0.6830378157853444\n",
            "Recall: 0.6961458499920038\n",
            "F1 Score: 0.689529542214478\n",
            "Confusion Matrix:\n",
            " [[3647 2020]\n",
            " [1900 4353]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.64      0.65      5667\n",
            "           1       0.68      0.70      0.69      6253\n",
            "\n",
            "    accuracy                           0.67     11920\n",
            "   macro avg       0.67      0.67      0.67     11920\n",
            "weighted avg       0.67      0.67      0.67     11920\n",
            "\n",
            "\n",
            "ðŸ“Š Naive Bayes Results\n",
            "----------------------------------------\n",
            "Accuracy: 0.7139261744966443\n",
            "Precision: 0.7266060895903077\n",
            "Recall: 0.7289301135454982\n",
            "F1 Score: 0.7277662462078875\n",
            "Confusion Matrix:\n",
            " [[3952 1715]\n",
            " [1695 4558]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.70      0.70      5667\n",
            "           1       0.73      0.73      0.73      6253\n",
            "\n",
            "    accuracy                           0.71     11920\n",
            "   macro avg       0.71      0.71      0.71     11920\n",
            "weighted avg       0.71      0.71      0.71     11920\n",
            "\n",
            "\n",
            "ðŸ“Š Decision Tree Results\n",
            "----------------------------------------\n",
            "Accuracy: 0.6646812080536912\n",
            "Precision: 0.6788205453392517\n",
            "Recall: 0.6847913001759156\n",
            "F1 Score: 0.6817928508876682\n",
            "Confusion Matrix:\n",
            " [[3641 2026]\n",
            " [1971 4282]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.64      0.65      5667\n",
            "           1       0.68      0.68      0.68      6253\n",
            "\n",
            "    accuracy                           0.66     11920\n",
            "   macro avg       0.66      0.66      0.66     11920\n",
            "weighted avg       0.66      0.66      0.66     11920\n",
            "\n",
            "\n",
            "ðŸ“Š Random Forest Results\n",
            "----------------------------------------\n",
            "Accuracy: 0.7394295302013423\n",
            "Precision: 0.7534224512803994\n",
            "Recall: 0.7481209019670558\n",
            "F1 Score: 0.7507623174450329\n",
            "Confusion Matrix:\n",
            " [[4136 1531]\n",
            " [1575 4678]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.73      0.73      5667\n",
            "           1       0.75      0.75      0.75      6253\n",
            "\n",
            "    accuracy                           0.74     11920\n",
            "   macro avg       0.74      0.74      0.74     11920\n",
            "weighted avg       0.74      0.74      0.74     11920\n",
            "\n",
            "\n",
            "ðŸ“Š Gradient Boosting Results\n",
            "----------------------------------------\n",
            "Accuracy: 0.7551174496644295\n",
            "Precision: 0.7658692185007975\n",
            "Recall: 0.7679513833359988\n",
            "F1 Score: 0.76690888764673\n",
            "Confusion Matrix:\n",
            " [[4199 1468]\n",
            " [1451 4802]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.74      0.74      5667\n",
            "           1       0.77      0.77      0.77      6253\n",
            "\n",
            "    accuracy                           0.76     11920\n",
            "   macro avg       0.75      0.75      0.75     11920\n",
            "weighted avg       0.76      0.76      0.76     11920\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Define all models\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
        "    \"K-Nearest Neighbors\": KNeighborsClassifier(n_neighbors=5),\n",
        "    \"Naive Bayes\": GaussianNB(),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
        "}\n",
        "\n",
        "# Function to evaluate and print metrics\n",
        "def evaluate_model(name, model, X_train, y_train, X_val, y_val):\n",
        "    model.fit(X_train, y_train)\n",
        "    preds = model.predict(X_val)\n",
        "\n",
        "    print(f\"\\nðŸ“Š {name} Results\")\n",
        "    print(\"-\" * 40)\n",
        "    print(\"Accuracy:\", accuracy_score(y_val, preds))\n",
        "    print(\"Precision:\", precision_score(y_val, preds))\n",
        "    print(\"Recall:\", recall_score(y_val, preds))\n",
        "    print(\"F1 Score:\", f1_score(y_val, preds))\n",
        "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_val, preds))\n",
        "    print(\"Classification Report:\\n\", classification_report(y_val, preds))\n",
        "\n",
        "# Loop through models and evaluate\n",
        "for name, model in models.items():\n",
        "    evaluate_model(name, model, X_train, y_train, X_val, y_val)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "UmgVAxEubnx4",
        "outputId": "c31a1d9c-56d4-42be-e272-c622db64916b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Employee ID  Age  Gender  Years at Company  Job Role  Monthly Income  \\\n",
              "0             8410   31       0                19         0            5390   \n",
              "1            64756   59       1                 4         1            5534   \n",
              "2            30257   24       1                10         2            8159   \n",
              "3            65791   36       1                 7         0            3989   \n",
              "4            65026   56       0                41         0            4821   \n",
              "...            ...  ...     ...               ...       ...             ...   \n",
              "14895        16243   56       1                42         2            7830   \n",
              "14896        47175   30       1                15         0            3856   \n",
              "14897        12409   52       0                 5         0            5654   \n",
              "14898         9554   18       0                 4         0            5276   \n",
              "14899        73042   59       1                48         0            3774   \n",
              "\n",
              "       Work-Life Balance  Job Satisfaction  Performance Rating  \\\n",
              "0                      3                 1                   2   \n",
              "1                      0                 2                   0   \n",
              "2                      2                 2                   0   \n",
              "3                      2                 2                   3   \n",
              "4                      1                 3                   2   \n",
              "...                  ...               ...                 ...   \n",
              "14895                  0                 1                   2   \n",
              "14896                  2                 1                   2   \n",
              "14897                  2                 3                   1   \n",
              "14898                  1                 2                   2   \n",
              "14899                  2                 2                   1   \n",
              "\n",
              "       Number of Promotions  ...  Employee Recognition  Attrition  is_train  \\\n",
              "0                         2  ...                     1          1         1   \n",
              "1                         3  ...                     0          1         1   \n",
              "2                         0  ...                     0          1         1   \n",
              "3                         1  ...                     1          1         1   \n",
              "4                         0  ...                     1          1         1   \n",
              "...                     ...  ...                   ...        ...       ...   \n",
              "14895                     0  ...                     1          1         0   \n",
              "14896                     2  ...                     1          0         0   \n",
              "14897                     0  ...                     2          0         0   \n",
              "14898                     0  ...                     2          1         0   \n",
              "14899                     1  ...                     3          0         0   \n",
              "\n",
              "       Tenure_Ratio  Promotion_Rate  Distance_Category  Age_Group  \\\n",
              "0          0.211111        0.100000                  2          1   \n",
              "1          0.181818        0.600000                  2          3   \n",
              "2          0.133333        0.000000                  1          0   \n",
              "3          0.137255        0.125000                  2          1   \n",
              "4          0.594203        0.000000                  3          3   \n",
              "...             ...             ...                ...        ...   \n",
              "14895      0.688525        0.000000                  3          3   \n",
              "14896      0.714286        0.125000                  3          0   \n",
              "14897      0.625000        0.000000                  0          3   \n",
              "14898      0.666667        0.000000                  1          0   \n",
              "14899      0.403361        0.020408                  3          3   \n",
              "\n",
              "       Income_per_Level  Work_Life_Satisfaction  Performance_Recognition_Score  \n",
              "0                2695.0                     2.0                            1.5  \n",
              "1                2767.0                     1.0                            0.0  \n",
              "2                4079.5                     2.0                            0.0  \n",
              "3                1994.5                     2.0                            2.0  \n",
              "4                1607.0                     2.0                            1.5  \n",
              "...                 ...                     ...                            ...  \n",
              "14895            2610.0                     0.5                            1.5  \n",
              "14896            3856.0                     1.5                            1.5  \n",
              "14897            2827.0                     2.5                            1.5  \n",
              "14898            2638.0                     1.5                            2.0  \n",
              "14899            1887.0                     2.0                            2.0  \n",
              "\n",
              "[74498 rows x 32 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1b671ad3-9821-4cb5-852d-ea4582180853\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Employee ID</th>\n",
              "      <th>Age</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Years at Company</th>\n",
              "      <th>Job Role</th>\n",
              "      <th>Monthly Income</th>\n",
              "      <th>Work-Life Balance</th>\n",
              "      <th>Job Satisfaction</th>\n",
              "      <th>Performance Rating</th>\n",
              "      <th>Number of Promotions</th>\n",
              "      <th>...</th>\n",
              "      <th>Employee Recognition</th>\n",
              "      <th>Attrition</th>\n",
              "      <th>is_train</th>\n",
              "      <th>Tenure_Ratio</th>\n",
              "      <th>Promotion_Rate</th>\n",
              "      <th>Distance_Category</th>\n",
              "      <th>Age_Group</th>\n",
              "      <th>Income_per_Level</th>\n",
              "      <th>Work_Life_Satisfaction</th>\n",
              "      <th>Performance_Recognition_Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8410</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "      <td>5390</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.211111</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2695.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>64756</td>\n",
              "      <td>59</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>5534</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.181818</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2767.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>30257</td>\n",
              "      <td>24</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>8159</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4079.5</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>65791</td>\n",
              "      <td>36</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>3989</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.137255</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1994.5</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>65026</td>\n",
              "      <td>56</td>\n",
              "      <td>0</td>\n",
              "      <td>41</td>\n",
              "      <td>0</td>\n",
              "      <td>4821</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.594203</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1607.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14895</th>\n",
              "      <td>16243</td>\n",
              "      <td>56</td>\n",
              "      <td>1</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>7830</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.688525</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2610.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14896</th>\n",
              "      <td>47175</td>\n",
              "      <td>30</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>3856</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3856.0</td>\n",
              "      <td>1.5</td>\n",
              "      <td>1.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14897</th>\n",
              "      <td>12409</td>\n",
              "      <td>52</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>5654</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2827.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>1.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14898</th>\n",
              "      <td>9554</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>5276</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2638.0</td>\n",
              "      <td>1.5</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14899</th>\n",
              "      <td>73042</td>\n",
              "      <td>59</td>\n",
              "      <td>1</td>\n",
              "      <td>48</td>\n",
              "      <td>0</td>\n",
              "      <td>3774</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.403361</td>\n",
              "      <td>0.020408</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1887.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>74498 rows Ã— 32 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1b671ad3-9821-4cb5-852d-ea4582180853')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1b671ad3-9821-4cb5-852d-ea4582180853 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1b671ad3-9821-4cb5-852d-ea4582180853');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-5775178c-6421-4e68-9968-dca7cdf5573c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5775178c-6421-4e68-9968-dca7cdf5573c')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-5775178c-6421-4e68-9968-dca7cdf5573c button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_44010294-fc7b-4906-bc69-56a4d37c8f53\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('combined_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_44010294-fc7b-4906-bc69-56a4d37c8f53 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('combined_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "combined_df"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "combined_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JJ12uGzTbo7F"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier, VotingClassifier,BaggingClassifier\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "#Importing ensemble models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zFvPX0iAt4A_"
      },
      "outputs": [],
      "source": [
        "ensemble_models = {\n",
        "    \"AdaBoost\": AdaBoostClassifier(n_estimators=150, random_state=42,learning_rate=1),\n",
        "    \"XGBoost\": xgb.XGBClassifier(n_estimators=200, learning_rate=0.1, random_state=42, use_label_encoder=False, eval_metric='logloss',max_depth=3),\n",
        "    \"LightGBM\": lgb.LGBMClassifier(n_estimators=50, learning_rate=0.1, random_state=42,num_leaves=31),\n",
        "    \"Bagging\": BaggingClassifier(n_estimators=100, random_state=42),\n",
        "\n",
        "    \"Voting Ensemble (Soft)\": VotingClassifier(\n",
        "        estimators=[\n",
        "            ('lr', LogisticRegression(max_iter=1000)),\n",
        "            ('rf', RandomForestClassifier(n_estimators=100)),\n",
        "            ('gb', GradientBoostingClassifier(n_estimators=100))\n",
        "        ],\n",
        "        voting='soft',weights=[1,2,1]\n",
        "    )\n",
        "}\n",
        "#Defining models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSj_pjNbvLh6",
        "outputId": "ee3aebbc-a731-438e-f8e9-df500eb0e52a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“Š AdaBoost Results\n",
            "----------------------------------------\n",
            "Accuracy: 0.7572147651006711\n",
            "Precision: 0.7673937271135169\n",
            "Recall: 0.7708300015992323\n",
            "F1 Score: 0.7691080261688208\n",
            "Confusion Matrix:\n",
            " [[4206 1461]\n",
            " [1433 4820]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.74      0.74      5667\n",
            "           1       0.77      0.77      0.77      6253\n",
            "\n",
            "    accuracy                           0.76     11920\n",
            "   macro avg       0.76      0.76      0.76     11920\n",
            "weighted avg       0.76      0.76      0.76     11920\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:57:48] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“Š XGBoost Results\n",
            "----------------------------------------\n",
            "Accuracy: 0.7561241610738255\n",
            "Precision: 0.7690575747828884\n",
            "Recall: 0.7647529185990725\n",
            "F1 Score: 0.7668992061582872\n",
            "Confusion Matrix:\n",
            " [[4231 1436]\n",
            " [1471 4782]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.75      0.74      5667\n",
            "           1       0.77      0.76      0.77      6253\n",
            "\n",
            "    accuracy                           0.76     11920\n",
            "   macro avg       0.76      0.76      0.76     11920\n",
            "weighted avg       0.76      0.76      0.76     11920\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 25007, number of negative: 22671\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006498 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1938\n",
            "[LightGBM] [Info] Number of data points in the train set: 47678, number of used features: 32\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.524498 -> initscore=0.098069\n",
            "[LightGBM] [Info] Start training from score 0.098069\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“Š LightGBM Results\n",
            "----------------------------------------\n",
            "Accuracy: 0.7536073825503355\n",
            "Precision: 0.7678513731825525\n",
            "Recall: 0.7601151447305293\n",
            "F1 Score: 0.7639636743550591\n",
            "Confusion Matrix:\n",
            " [[4230 1437]\n",
            " [1500 4753]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.75      0.74      5667\n",
            "           1       0.77      0.76      0.76      6253\n",
            "\n",
            "    accuracy                           0.75     11920\n",
            "   macro avg       0.75      0.75      0.75     11920\n",
            "weighted avg       0.75      0.75      0.75     11920\n",
            "\n",
            "\n",
            "ðŸ“Š Bagging Results\n",
            "----------------------------------------\n",
            "Accuracy: 0.7327181208053691\n",
            "Precision: 0.7511875511875512\n",
            "Recall: 0.7334079641771949\n",
            "F1 Score: 0.7421912930894967\n",
            "Confusion Matrix:\n",
            " [[4148 1519]\n",
            " [1667 4586]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.73      0.72      5667\n",
            "           1       0.75      0.73      0.74      6253\n",
            "\n",
            "    accuracy                           0.73     11920\n",
            "   macro avg       0.73      0.73      0.73     11920\n",
            "weighted avg       0.73      0.73      0.73     11920\n",
            "\n",
            "\n",
            "ðŸ“Š Voting Ensemble (Soft) Results\n",
            "----------------------------------------\n",
            "Accuracy: 0.7454697986577181\n",
            "Precision: 0.7559230402289712\n",
            "Recall: 0.7602750679673757\n",
            "F1 Score: 0.758092808164567\n",
            "Confusion Matrix:\n",
            " [[4132 1535]\n",
            " [1499 4754]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.73      0.73      5667\n",
            "           1       0.76      0.76      0.76      6253\n",
            "\n",
            "    accuracy                           0.75     11920\n",
            "   macro avg       0.74      0.74      0.74     11920\n",
            "weighted avg       0.75      0.75      0.75     11920\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for name, model in ensemble_models.items():\n",
        "    evaluate_model(name, model, X_train, y_train, X_val, y_val)\n",
        "#Function to loop and evaluate the models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uVR7JSEV2B5j"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4187e6d7"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define parameter grids for each ensemble model\n",
        "param_grids = {\n",
        "    \"AdaBoost\": {\n",
        "        'n_estimators': [50, 150, 200],\n",
        "        'learning_rate': [0.01, 0.1, 1]\n",
        "    },\n",
        "    \"XGBoost\": {\n",
        "        'n_estimators': [50, 120, 200],\n",
        "        'learning_rate': [0.01, 0.1, 0.2],\n",
        "        'max_depth': [3, 5, 7]\n",
        "    },\n",
        "    \"LightGBM\": {\n",
        "        'n_estimators': [50, 100, 150],\n",
        "        'learning_rate': [0.01, 0.1, 0.2],\n",
        "        'num_leaves': [31, 50, 100]\n",
        "    },\n",
        "\n",
        "    \"Voting Ensemble (Soft)\": {\n",
        "\n",
        "        'weights': [[1, 1, 1], [1, 2, 1], [2, 1, 1]]\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ab935515",
        "outputId": "f3b666f9-2d44-4613-ed02-9ad9565ab104"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ðŸ”¬ Tuning AdaBoost...\n",
            "Best parameters for AdaBoost: {'learning_rate': 1, 'n_estimators': 150}\n",
            "Best cross-validation accuracy for AdaBoost: 0.7592180873552787\n",
            "\n",
            "ðŸ”¬ Tuning XGBoost...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:05:15] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best parameters for XGBoost: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200}\n",
            "Best cross-validation accuracy for XGBoost: 0.7577709146314163\n",
            "\n",
            "ðŸ”¬ Tuning LightGBM...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Number of positive: 25007, number of negative: 22671\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006614 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1579\n",
            "[LightGBM] [Info] Number of data points in the train set: 47678, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.524498 -> initscore=0.098069\n",
            "[LightGBM] [Info] Start training from score 0.098069\n",
            "Best parameters for LightGBM: {'learning_rate': 0.1, 'n_estimators': 50, 'num_leaves': 31}\n",
            "Best cross-validation accuracy for LightGBM: 0.755316899843887\n",
            "\n",
            " skipping tuning for Bagging as no parameter grid is defined.\n",
            "\n",
            "ðŸ”¬ Tuning Voting Ensemble (Soft)...\n",
            "Best parameters for Voting Ensemble (Soft): {'weights': [1, 2, 1]}\n",
            "Best cross-validation accuracy for Voting Ensemble (Soft): 0.7522756824868541\n"
          ]
        }
      ],
      "source": [
        "tuned_models = {}\n",
        "\n",
        "for name, model in ensemble_models.items():\n",
        "    if name in param_grids:\n",
        "        print(f\"\\n Tuning {name}...\")\n",
        "        grid_search = GridSearchCV(model, param_grids[name], cv=3, scoring='accuracy', n_jobs=-1)\n",
        "        grid_search.fit(X_train, y_train)\n",
        "\n",
        "        print(f\"Best parameters for {name}: {grid_search.best_params_}\")\n",
        "        print(f\"Best cross-validation accuracy for {name}: {grid_search.best_score_}\")\n",
        "\n",
        "        tuned_models[name] = grid_search.best_estimator_\n",
        "    else:\n",
        "        print(f\"\\n skipping tuning for {name} as no parameter grid is defined.\")\n",
        "        tuned_models[name] = model # Use the default model if no grid is defined\n",
        "\n",
        "#Using GridSearchCV to find the optimal hyperparameters for the ensemble models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "46c0723e"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, BaggingClassifier\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "\n",
        "# Define parameter grids for all models\n",
        "param_grids_ml = {\n",
        "    \"Logistic Regression\": {\n",
        "        'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
        "        'penalty': ['l1', 'l2'],\n",
        "        'max_iter': [100, 150, 200]\n",
        "    },\n",
        "    \"K-Nearest Neighbors\": {\n",
        "        'n_neighbors': [3, 5, 7, 9],\n",
        "        'weights': ['uniform', 'distance'],\n",
        "        'metric': ['euclidean', 'manhattan','minkowski']\n",
        "    },\n",
        "    \"Naive Bayes\": {}, # GaussianNB generally doesn't have hyperparameters to tune\n",
        "    \"Decision Tree\": {\n",
        "        'max_depth': [None, 5, 10, 15],\n",
        "        'min_samples_split': [2, 5, 10],\n",
        "        'criterion': ['gini', 'entropy','log_loss']\n",
        "    },\n",
        "    \"Random Forest\": {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'max_depth': [None, 5, 10, 15]\n",
        "    },\n",
        "    \"Gradient Boosting\": {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'learning_rate': [0.01, 0.1, 0.2]\n",
        "    }\n",
        "\n",
        "}\n",
        "\n",
        "#Defining parameter grid for the ML models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8U5pHV9DBIT",
        "outputId": "dadccfd5-69dd-4a1f-f1ff-9d83c2427cc5"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ðŸ”¬ Tuning Logistic Regression...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
            "54 fits failed out of a total of 108.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "54 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1389, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py\", line 1193, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py\", line 63, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or None penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [       nan 0.73245519        nan 0.73245519        nan 0.73245519\n",
            "        nan 0.73186791        nan 0.73186791        nan 0.73186791\n",
            "        nan 0.73119675        nan 0.73119675        nan 0.73119675\n",
            "        nan 0.73100799        nan 0.73100799        nan 0.73100799\n",
            "        nan 0.73098702        nan 0.73098702        nan 0.73098702\n",
            "        nan 0.73098702        nan 0.73098702        nan 0.73098702]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters for Logistic Regression: {'C': 0.001, 'max_iter': 100, 'penalty': 'l2'}\n",
            "Best cross-validation accuracy for Logistic Regression: 0.7324551885275105\n",
            "\n",
            "ðŸ”¬ Tuning K-Nearest Neighbors...\n",
            "Best parameters for K-Nearest Neighbors: {'metric': 'manhattan', 'n_neighbors': 9, 'weights': 'uniform'}\n",
            "Best cross-validation accuracy for K-Nearest Neighbors: 0.6951424556558802\n",
            "\n",
            "ðŸ”¬ Tuning Naive Bayes...\n",
            "Best parameters for Naive Bayes: {}\n",
            "Best cross-validation accuracy for Naive Bayes: 0.7191996354490527\n",
            "\n",
            "ðŸ”¬ Tuning Decision Tree...\n",
            "Best parameters for Decision Tree: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 2}\n",
            "Best cross-validation accuracy for Decision Tree: 0.7284910960704801\n",
            "\n",
            "ðŸ”¬ Tuning Random Forest...\n",
            "Best parameters for Random Forest: {'max_depth': 15, 'n_estimators': 200}\n",
            "Best cross-validation accuracy for Random Forest: 0.746864348678545\n",
            "\n",
            "ðŸ”¬ Tuning Gradient Boosting...\n",
            "Best parameters for Gradient Boosting: {'learning_rate': 0.2, 'n_estimators': 100}\n",
            "Best cross-validation accuracy for Gradient Boosting: 0.7583581581134181\n"
          ]
        }
      ],
      "source": [
        "tuned_models_ml = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    if name in param_grids_ml:\n",
        "        print(f\"\\nðŸ”¬ Tuning {name}...\")\n",
        "        grid_search = GridSearchCV(model, param_grids_ml[name], cv=3, scoring='accuracy', n_jobs=-1)\n",
        "        grid_search.fit(X_train, y_train)\n",
        "\n",
        "        print(f\"Best parameters for {name}: {grid_search.best_params_}\")\n",
        "        print(f\"Best cross-validation accuracy for {name}: {grid_search.best_score_}\")\n",
        "\n",
        "        tuned_models_ml[name] = grid_search.best_estimator_\n",
        "    else:\n",
        "        print(f\"\\n skipping tuning for {name} as no parameter grid is defined.\")\n",
        "        tuned_models_ml[name] = model # Use the default model if no grid is defined\n",
        "\n",
        "#Finding optimal hyperparameter for ML models"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VMYrceFuzTr-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}